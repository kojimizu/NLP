---
title: "Time Series Analysis"
author: "KM"
date: "2018.07.06ï½¥"
output:
  word_document: default
  html_document: default
---

# Section 1
## LEcture 3: Main Functions

(1) Basic functions in R Base are:
- decompose()
- stl()
- arima()
- HolWinters()
- acf(), pacf()
- plot()
- ts()

(2) Add-on package - `forecast` package
```{r}
# package load
library(forecast)
library(ggplot2)
```

### Forecast structure 
Function `forecast()` + standard model = Forecasting

Standar model is (1) ARIMA, (2) Sesonal decomposition, (3) Exponential smoothing, and (4) simple models (e.g., naive mean).

Forecasting Results are always in the same structure regardless of the model(which are different from function `predict()`).

In the `Forecast` library, automatic parameter selection is available both for the ARIMA model and the exponential smoothing. 

### ARIMA models in Library `Forecast`
auto.arima(time_series) -> most suitable ARIMA model
`auto.arima` sets the complexity with the arguments `stepwise` and `approximation`. WE can get a list of possible models, as well as the information criteria.

Arima(time_series)
we could set the parameters manually (manual parameter selecion). In the manual selection, we look fro autocorrelation based on the `acf()` and `pacf()` plots. we adjust the model by `time_series` - `lags` until no more autocorrelation.

### Exponential smooothing in Library `Forecast`
Automatic function - `ets()`
manual functions: `ses()`, `hw()`, `holt()`

### Plotting with Library `Forrecast`

R Base Plots:
- `plot()`
- `monthplot()`
- `seasonplot()`

ggplot2 plots:
- `autoplot()`
- `ggmothplot()`
- `ggseasonplot()`

### Model comparison with Library `Forecast`
`accruacy()`
getting the model accuracy with a training and a test set.

`tsCV()`
time series cross validation for small datasets.

### Other packages 
we would use `getSymbols()`, `quantmod()` and `xts()` packages.
```{r}
# install.packages("quantmod")
# install.packages("xts")
```

## Lecture 4: Supporting Resources
R Time series Task View 
curated by Rob Hyndman (Blog on Otexts.org)
https://robjhyndman.com/

Vignetts 
some packages come with vignettes (description, PDF)

Free e-Books "Forecasting: Principles and Practice"
https://otexts.org/fpp2/index.html
https://robjhyndman.com/seminars/uwa2017/

R Community on Stackoverflow.com
https://stackoverflow.com/questions/tagged/r

## Lecture 5: Course Link List
Time Series Task View:
https://cran.r-project.org/web/views/TimeSeries.html

Blog, Ebook and Forecast Documentation by Rob Hyndman:
https://otexts.org/fpp2/intro.html

Stackoverflow Community:
https://stackoverflow.com/questions

Singapur Data of Project I:
https://docs.google.com/spreadsheets/d/1frieoKODnD9sX3VCZy5c3QAjBXMY-vN7k_I9gR-gcU8/pub
http://www.gapminder.org/data/

German Inflation Data of Project II:
https://www.statbureau.org/en/germany/inflation-tables

# Section 2: Project I Trending Data:Singapur Labor Force Participation Rate
## LEcture 6: Importing the data

Uneployment rate
- Used for propaganda purposes
- Easy to manipulate
- Who is unemployed?
- Who doesn't show up in the metric?

Labor Force Participatin Rate
- Harder to manipulate
- Ratio of people in the work force vs available people of a particular age range
- Factors for manipulation /bias
https://www.gapminder.org/data/

We need to compara things that are the same or similar level. Unbalanced comparisons require well thought out methodology to adjust for a mismatch. 
```{r}
# package load
library(forecast)
library(ggplot2)
library(quantmod)
library(xts)

# Import with scan
# "70.19999695	71.09999847	71.69999695	72.30000305	73.09999847	72.90000153	74.40000153	75.40000153	76	76.90000153	77.40000153	78.19999695	78.90000153	78.69999695	79	78	80	79.80000305	80.30000305	80.5	80.69999695	81.09999847	81.5	81.90000153	82.30000305	82.69999695	83.19999695	83.5"
# singapur=scan()
# singapur
singapur <-c(70.19999695,	71.09999847,	71.69999695,	72.30000305,	73.09999847,	72.90000153,	74.40000153,	75.40000153,	76,	76.90000153,	77.40000153,	78.19999695,	78.90000153,	78.69999695,	79,	78,	80,	79.80000305,	80.30000305,	80.5,	80.69999695,	81.09999847,	81.5,	81.90000153,	82.30000305,	82.69999695,	83.19999695,	83.5)
# item 28 are shown by this code 
singapur
singapur <- ts(singapur,start=1980)
singapur
plot(singapur,ylab="Labor Force Participation Rate")
```

From the above chart, the possible models are:
- ARIMA
- Holt linear trend method

However, one feature of this data is that the values cannnot exceed 100% in the model.There needs to be some press hold. Holt method has a nice damping parameter (holt()).

## Lecture 7: Mission Statement
From this lecture, we would focous on the theory and practical implementation through the four questions. 
- How to handle time series with trend?  
- Which methods are available?  
- What are the pitfalls?  
- How to visualize time series data?  

The process is 
1. Get the dataset  
2. Get the mission statement  
3. Work on the project  
4. Proceed with lectures and check the work  

The potential models are:  
- Linear trend model with `holt()`  
  - With damping paramter  
  - Without damping parameter  
- ARIMA model  

These models can be applied for forecasts, but with pitfalls, visualizations, alternatives. 

For applying the above models, we just need:   
(1) Libraries "forecast" and "ggplo2" + R base functions  
(2) Resources from the introductory section  

## Lecture 9: Exponential smoothing

Forecast package
- Simple exponential smooothing: `ses()`
- Holt's linear trend model]: `holt()` +damped
- Holt-Winters seasonal method: `hw()`
- Automated exponential smooothing: `ets()`

Holt linear trend model is:
$$
Y_{t+h|t} = l_t + hb_t  
$$  
-  $Y_{t+h|t}$: estimated forecast value at $t$ time point  
- $l$: level value at $t$ time point  
- $hb_t$: trend value at $t$ time point multiplied by $h$  

Should the model react only to recent data or should it consider older data as well?
-> Smoothing parameters

Smoothing parameters of a Holt Linear Trend Model are:  
1. $\alpha$:smoothing parameter for the level
2. $\beta$:smoothing parameter for the trend

The closer the smoothing parameter is to zero, the model becomes smoooth model (older date is consdered too), otherwise (close to 1) the model is the reactive model, heavily relying on recent data. 

## Lecture 10: The Holt Linear Trend Model 

In the Project I, we use `holt linear trend model`. 
In practice, we firstly activate the library `forecast`, and use the holt() function to create the model.   
- data=the time series to model  
- h=forecast length  
```{r 10.1}

# holt(data, h=x, damped=FALSE, level=c(80,95),fan=FALSE,initial=c("optimal","simple"),exponential=FALSE,alpha=NULL,beta=NULL,phi=NULL,lambda=NULL)

library(forecast)
holt_trend <- holt(singapur,h=5)
summary(holt_trend)
plot(holt_trend)
```

Most of the above arguments are the same for `ses()` and `hw()`.
By `summary()` function, we can obtain smoothing parameters, and initial state values. In the Singapur case, the participation cannot exceed

If we encounter simiular situation, exact parameters and thresholds. They know the literature, and experience, background information. 

For the above case, we use the damped argument. In the Holt linear trend model, the smoothing parameters are:   
- $\alpha$: smoothing parameter for the level  `alpha=`
- $\beta$: smoothing parameter for the trend  `beta=`
- $\phi$: damping parameter 0<$\phi$<1  `phi=`

We can easily adjust the model by the damping parameter.

If $\phi$ is one, its close to the original slope of the Holt trend model. If the $\phi$ is between 0.85 to 0.95, it is the generally recommended range of phi. If the $\phi$ is close to 0, its a flattened curve. 

**When the `damped` parameter is used, the slope of the trend cannnot be constant: It changes over time**

```{r 10.2}
#phi auto generated
plot(holt(singapur,h=15,damped=T))
# To see the generated value for phi: phi=0.96
summary(holt(singapur,h=15,damped=T))

# manual setting of phi
plot(holt(singapur,h=15,damped=T,phi=0.8))

# ARIMA auto generated
singapurarima=auto.arima(singapur)
summary(singapurarima)
```

## Lecture 11: The ARIMA model - Project I
The Box Jenkins models are standard modeling system for time series model. There are three parameters

- AR: Autoregressive such as seasonality, trend `P`
- |: Integreation - defferencing of the dataset `D`
- MA: Moving average - movement around a constant mean `Q`

The ARIMA model is very flexible for explaining:
- Random Walk
- Exponential Smooothing
- Autoregressive models such as AR(1), ARIMA(1,0,0)
- Moving average (MA(1), ARIMA(0,0,1))

The labour participation rate can be modeled by ARIMA. For that, we need to take into consideration, trending, autocorrelation (AR). Please note that, it seems there is no no moving average, seasonality, thus no differencing is needed.

With the `forecast` package, we can model the ARIMA model with manual parameter selection, and automatic parameter selection.
<`forecast` package>
- `Arima()`
- `auto.arima()`
```{r 11.1}
# ARIMA auto generated
singapurarima = auto.arima(singapur)
summary(singapurarima)

## ARIMA(1,1,0) with drift
## Summary output is same as the holt model
## The buttom shows that training set error measures

plot(forecast(singapurarima,h=5),ylab="Labor Participation Rate")

# The above setting might work for short term period
# Flatting curve needs to be designed

# Exact calculation of Arima parameters
auto.arima(singapur,stepwise = F,approximation = F)

```

## Lecture 12: Comparison between ggplot
The visualization should be simple. 

The plotting methods with `forecast` package are: 
- `plot()`:
quick and simple graphs with R base
- `autoplot()` and `autolayer()`:
Visually improved plots with libraries `ggplot2` and `forecast`.

The latest `forecast` package is in collaboration with the `ggplot` package. IN this lecture, we would visualize the Singapur data with the `ggplot` package.
```{r 12-1}
# model setting
# 1: Holttrend model
library(forecast)
holt_trend = holt(singapur,h=10)
holtdamped=holt(singapur,h=10,damped=T)
arimafore=forecast(auto.arima(singapur),h=10)
```

- Functions: `autoplot()` + `autolayer()`
- activate the libraries `ggplot` and `forecast`

<Procedure>
1. We first return a line graph(time series) by model. In the visualization, 
2. Models are added layer by later by using autolayer() from the `forecast` package.In addition, `$mean` extracts the forecast values from the model.
3. Axis labels are added with `+`.
4. The legend is added.

```{r 12-2}
library(ggplot2)
autoplot(singapur)+
  forecast::autolayer(holt_trend$mean,series="Holt Linear Trend")+
  forecast::autolayer(holtdamped$mean,series="Holt Damped Trend")+
  forecast::autolayer(arimafore$mean,series="ARIMA")+
  xlab("year")+ylab("Labour Force Participation Rage Age 25-54")+
  guides(colour=guide_legend(title="Forecast Method"))+
  theme(legend.position = c(0.8,0.2))+
  ggtitle("Singapur")+
  theme(plot.title = element_text(family="Times",hjust=0.5,color="blue",face="bold",size=15))
```

## Lecture 13:  In-Sample forecast vs actual data
The idea is to reconstruct the plot, and we compare the original data with in-sample values of the models.In comparision, we will color code the lines. Lastly, we adjust the tiles and labels.
```{r 13-1}
# package load
library(forecast)
library(ggplot2)

# models 
holttrend=holt(singapur,h=10)
holtdamped=holt(singapur,h=10,damped=T)
airmafore=forecast(auto.arima(singapur),h=10)

autoplot(singapur)+geom_line(size=2)+
  forecast::autolayer(holttrend$fitted,series="Holt Linear Trend",size=1.1)+
  forecast::autolayer(holtdamped$fitted,series="Holt Damped Trend",size=1.1)+
  forecast::autolayer(arimafore$fitted,series="ARIMA",size=1.1)+
  xlab("year")+ylab("Labour Force Participation Rate Age 25-54")+
  guides(colour=guide_legend(title="Forecast Method"))+
  theme(legend.position=c(0.8,0.2))+
  ggtitle("singapur")+theme(plot.title=element_text(family="Times",hjust=0.5,color="blue",face="bold",size=15))
```

# Section 3: Project II Seasonal data: monthly inflation rates of Germany
## Lecture 14: Getting familar with data 
Inflation rate is a measure of change in purchasing power per unit of money. It is also important to know how inflation moves along with other indicators.

We use a monthly inflation rate of Germany (Jany 2008 - Oct 2017) from ststbureau.org.
https://www.statbureau.org/
https://www.statbureau.org/en/germany/inflation-tables

The monthly rate should be more intuitive in the following comparison methods. 
- Oct 2017 vs Oct 2016:
Year on year rate (standard method)
- OCt 2017 vs Sept 2017:
Month on month rate (changes are easier to detect)

The inspecting the dataset comes from
1. No **trend** is present (constant mean)
2. **Seasonality** is present (seasonal decomposition, seasonal ARIMA, exponential smoothing)
3. Presence of **negative values** (multiplicative exponential smoothing models are excluded)
4. **Stable amplitude** (stable variance)

## Lecture 15: Importing the data
The general strucure of the dataset should be common. 

There are two things to keep in mind while importing 
- No headrs or row IDs 
- data needs to be arranged/sorted (preformating process)

Let's use a `scan()` function to import data.Only with this function, no timestamp is set yet. 
```{r 15-1}
# data load
mydata = scan()

# raw data
# -0.31	0.41	0.51	-0.2	0.61	0.2	0.61	-0.3	-0.1	-0.2	-0.51	0.41 -0.51	0.61	-0.2	0.1	-0.1	0.3	0	0.2	-0.3	0	-0.1	0.81 -0.6	0.4	0.5	0.1	-0.1	0	0.2	0.1	-0.1	0.1	0.1	0.6 -0.2	0.6	0.59	0	0	0.1	0.2	0.1	0.2	0	0.2	0.19 -0.1	0.68	0.58	-0.19	0	-0.19	0.39	0.38	0.1	0	0.1	0.29 -0.48	0.57	0.48	-0.47	0.38	0.09	0.47	0	0	-0.19	0.19	0.38 -0.56	0.47	0.28	-0.19	-0.09	0.28	0.28	0	0	-0.28	0	0 -1.03	0.85	0.47	0	0.09	-0.09	0.19	0	-0.19	0	0.09	-0.09 -0.84	0.38	0.75	-0.37	0.28	0.09	0.28	0	0.09	0.19	0.09	0.74 -0.64	0.65	0.18	0	-0.18	0.18	0.37	0.09	0.09	0	0.27	0.64

# timestamp
plot.ts(mydata)

# ts() function - ts data load
germaninfl=ts(mydata,start=2008,frequency = 12)
plot(germaninfl)

# basic structure
# ts(mydata, start=c(2008,3),frequency=12)

```

## Lecture 16: Mission statement
Seaonal time series data, we are focusing on (1) seasonality, and (2) cross-validation.Primarily, we can inport data by:ts(data, start=, frequency=)

This dataset is a monthly inflation rate of Germany, class=ts, frequency=!2, no trend with seasonal pattern. For dealing with seasonality, we should consider (1) seasonal decomposition, (2) exponential smooothing and (3) seasonal ARIMA. 

1. **Seasonal decomposition**
`decompose()` function is not allowed for the forecast. STL + ETL enables us to decompose for the forecast, which can be resembled by `stlf()`. 

2. **Sesonal ARIMA**
ARIMA(1,0,2)(0,1,1) or `auto.arima()` function

3. **Exponential smoothing**
get an automated exponential smoothing model by `est()` - automated or `hw()`.

Do these models have high accuracy? 
To answer this question, we should splot test/training set, and corss validate by `tsCV()`.

## LEcture 17: Project II Script
```{r}

# Data load
# mydata=scan()
plot.ts(mydata)

germaninfl=ts(mydata,start=2008,frequency = 12)
plot(germaninfl)

# Seasonal decomposition
decompose(germaninfl)
plot(decompose(germaninfl))

# using the stl method
plot(stl(germaninfl,s.window = 7))

# stl forecasting
library(forecast)
plot(stlf(germaninfl,method="ets"))

# comparison with a standard est forecast
plot(forecast(ets(germaninfl),h=24))

# using autoplot
library(ggplot2)
autoplot(stlf(germaninfl,method="ets"))

# Seasonal Arima(package forecast)
auto.arima(germaninfl,stepwise=T,
           approximation=F,trace=T)

# Getting an object
germaninflarima = auto.arima(germaninfl,stepwise=T,
                             approximation = F,trace=T)

# forecast
forec=forecast(germaninflarima)
plot(forec)

# exponential smoothing with ets
# auto generated
ets(germaninfl)
# forecast plot
germaninflets=ets(germaninfl)
plot(forecast(germaninflets,h=60))

# comparison with seasonal Holt Winters model
plot(hw(germaninfl,h=60))

# cross validation of 2 models
germnainflets=ets(germaninfl)
germaninflarima=auto.arima(germaninfl,
                           stepwise=T,
                           approximation=F,
                           trace=T)

## Function definition
forecastets = function(x,h){
  forecast(ets(x),h=h)
}

forecastarima = function(x,h){
  forecast(auto.arima(x),stepwise=T,approximation=F,h=h)
}

esterror=tsCV(germaninfl,forecastets,h=1)
arimaerror=tsCV(germaninfl,forecastarima,h=1)

mean(esterror^2,na.rm=T)
mean(arimaerror^2,na.rm=T)
```

## Lecsson 18: Seasonal Decomposition
Date:7/17
Seasonal decomposition is an old analytical method, but useful for dividing the data into its components:
- trend
- seasonality
- remainder/white noise

The seasonal decomposition is an additive/multiplicative model, and we can get q quick idea about the data. 

Note that there are several drawbacks:
(1) First few observations are NA
(2) Slow to catch fast rises
(3) Adopts a constant seasonal component

The basic functions are: `decompose()` and `stl()`.
```{r}
decompose(germaninfl)
plot(decompose(germaninfl))
```

Overall there is no clear trend of German inflation rate, however, from the seasonality (second from the below), we can see some pattern (Christmas period - high inflation due to mass parchasing behavior). 

The simple decomposition method is helpful, but the new methods for seasonal decomposition are:
- `x11()`
- `Seats()`
- `STL()`

As the benefits of the above new methods, they don't require omitting values (i.e., No NA values), and the seasonal part can be adjusted over time. 

(1) STL function
- Seaonsla and trend decomposition with LOESS
- Function of R base/data=time series
- Robust towards outlier
- Suitable toward an additive model (For multiplicative model, data transaformation is needed)
- Seaonanl and trend cycle may change overtime

Example:
stl(data,s.window=7)
- `s.window=`: number of required seasonal cycles to calculate changes for the seasonality (e.g., x>=7)
- `t.window=`: number of required seasonal cycles to calculate changes for the trend

```{r}
# plot visualization
plot(stl(germaninfl,s.window = 7))
# second to top: seasonality
```


### Create a forecast with STL decomposition
There are two approaches 
<Approach 1>
1. Use `stl()` on the data
2. Put the results into an object
3. Feed the objection into the `forecast.stl()` function

<Alternative approach 2>
1. Use the `stlf()` function on the data
2. USe the `method` argument

```{r}
library(forecast)

# stl forecasting + ETS
plot(stlf(germaninfl,method="ets"))

# comparison with a standard ets forecast
# peaks and slppes are different
plot(forecast(ets(germaninfl),h=24))

# using autoplot
library(ggplot2)
autoplot(stlf(germaninfl,method="ets"))
```

## Lecture 19: Seasonal ARIMA


















